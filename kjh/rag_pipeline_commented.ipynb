{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a62651",
   "metadata": {},
   "source": [
    "# RAG íŒŒì´í”„ë¼ì¸ (Elasticsearch + Sentenceâ€‘BERT + OpenAI GPT)\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì½”ë“œë¥¼ **ëª¨ë“  ì¤„ ì£¼ì„**ê³¼ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "ê° ì„¹ì…˜ë³„ë¡œ Markdown ì„¤ëª… â†’ Code ì…€ ìˆœì„œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d38202",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ëª¨ë¸ ì´ˆê¸°í™”\n",
    "í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”í›„ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import requests\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")     # í•œêµ­ì–´ SBERT ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5509fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ë¥˜ë©”ì‹œì§€ ì•ˆë‚˜ì˜¤ê²Œ ì„¤ì •\n",
    "import urllib3\n",
    "\n",
    "# InsecureRequestWarning ë„ê¸°\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80791d4a",
   "metadata": {},
   "source": [
    "### .env ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d097c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "ES_PASSWORD=os.getenv(\"ES_PASSWORD\")\n",
    "SOLAR_API_KEY=os.getenv(\"SOLAR_API_KEY\")\n",
    "SOLAR_API_URL=os.getenv(\"SOLAR_API_URL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c69952",
   "metadata": {},
   "source": [
    "## ì„ë² ë”© í•¨ìˆ˜\n",
    "1. get_embedding(sentences) í•¨ìˆ˜\n",
    "- sentences: í…ìŠ¤íŠ¸(ë˜ëŠ” í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸)ê°€ ë“¤ì–´ì˜¤ëŠ” ì…ë ¥.\n",
    "- model.encode(sentences): model ê°ì²´ (ë³´í†µ Sentence-BERT ê°™ì€ ì„ë² ë”© ëª¨ë¸)ì„ ì´ìš©í•´ì„œ ì…ë ¥ ë¬¸ì¥ë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "- ê²°ê³¼ì ìœ¼ë¡œ ë¬¸ì¥ í•˜ë‚˜ë‹¹ í•˜ë‚˜ì˜ ë²¡í„°ë¥¼ ë½‘ì•„ì£¼ëŠ” ì—­í• .\n",
    "\n",
    "2. get_embeddings_in_batches(docs, batch_size=100) í•¨ìˆ˜\n",
    "- docs: ì—¬ëŸ¬ ê°œì˜ ë¬¸ì„œë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸ì•¼. (ë¬¸ì„œ í•˜ë‚˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ, ì˜ˆ: {\"content\": \"ë‚´ìš©\"})\n",
    "- batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ 100ê°œ.\n",
    "- ì‘ë™ ë°©ì‹:\n",
    "    - ì „ì²´ ë¬¸ì„œë¥¼ batch_sizeë§Œí¼ ë‚˜ëˆ ì„œ,\n",
    "    - ê° ë°°ì¹˜ë§ˆë‹¤ ë¬¸ì„œì˜ \"content\"ë§Œ ë½‘ì•„,\n",
    "    - get_embedding()ìœ¼ë¡œ ì„ë² ë”©ì„ ê³„ì‚°í•˜ê³ ,\n",
    "    - ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ì–´ë¶™ì¸ë‹¤.\n",
    "\n",
    "ë§¤ ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•´ì„œ, \"ëª‡ ë²ˆì§¸ ë¬¸ì„œê¹Œì§€ ì²˜ë¦¬í–ˆëŠ”ì§€\" í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0062aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentences):               # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "    return model.encode(sentences)           # ëª¨ë¸ì„ ì´ìš©í•´ ë¬¸ì¥ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜\n",
    "\n",
    "\n",
    "def get_embeddings_in_batches(docs, batch_size=100):  # ë°°ì¹˜ ë‹¨ìœ„ ì„ë² ë”© ìƒì„±\n",
    "    batch_embeddings = []                              \n",
    "    for i in range(0, len(docs), batch_size):          # 0ë¶€í„° ëê¹Œì§€ batch_sizeì”© ìŠ¬ë¼ì´ì‹±\n",
    "        batch = docs[i:i + batch_size]                 # í˜„ì¬ ë°°ì¹˜ ì¶”ì¶œ\n",
    "        contents = [doc[\"content\"] for doc in batch]   # ë¬¸ì„œ ë³¸ë¬¸ë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ\n",
    "        embeddings = get_embedding(contents)           # ì„ë² ë”© ê³„ì‚°\n",
    "        batch_embeddings.extend(embeddings)            # ê²°ê³¼ ëˆ„ì \n",
    "        print(f'batch {i}')                            # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "    return batch_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6a770",
   "metadata": {},
   "source": [
    "## ES ì¸ë±ìŠ¤ ê´€ë¦¬\n",
    "1. create_es_index(index, settings, mappings)\n",
    "- index: ë§Œë“¤ê³  ì‹¶ì€ ì¸ë±ìŠ¤ ì´ë¦„ (ì˜ˆ: \"test\")\n",
    "- settings: ì•„ê¹Œ ë§Œë“  ë¶„ì„ê¸° ì„¤ì • (settings ë³€ìˆ˜)\n",
    "- mappings: ì•„ê¹Œ ë§Œë“  í•„ë“œ êµ¬ì¡° (mappings ë³€ìˆ˜)\n",
    "\n",
    "2. delete_es_index(index)\n",
    "- index: ì‚­ì œí•˜ê³  ì‹¶ì€ ì¸ë±ìŠ¤ ì´ë¦„.\n",
    "- ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ì‚­ì œ\n",
    "\n",
    "3. bulk_add(index, docs)\n",
    "- index: ë°ì´í„°ë¥¼ ì§‘ì–´ë„£ì„ ì¸ë±ìŠ¤ ì´ë¦„.\n",
    "- docs: ì—…ë¡œë“œí•  ë¬¸ì„œë“¤ ë¦¬ìŠ¤íŠ¸. (docëŠ” ë³´í†µ { \"content\": \"í…ìŠ¤íŠ¸\", \"embeddings\": [...] } í˜•íƒœ)\n",
    "- ì‘ë™ ë°©ì‹:\n",
    "    - ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ Elasticsearchê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” bulk ì‘ì—…ìš© ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¾¼ë‹¤.\n",
    "    - helpers.bulkë¥¼ ì‚¬ìš©í•´ì„œ í•œ ë²ˆì— ëŒ€ëŸ‰ ì—…ë¡œë“œí•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacaf9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_index(index, settings, mappings):        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "    if es.indices.exists(index=index):                 # ì´ë¯¸ ì¡´ì¬í•˜ë©´\n",
    "        es.indices.delete(index=index)                 # ì‚­ì œ í›„ ì¬ìƒì„±\n",
    "    es.indices.create(index=index,                    # ì¸ë±ìŠ¤ ìƒì„±\n",
    "                      settings=settings,\n",
    "                      mappings=mappings)\n",
    "\n",
    "def delete_es_index(index):                           # ì¸ë±ìŠ¤ ì‚­ì œ ë˜í¼\n",
    "    es.indices.delete(index=index)\n",
    "\n",
    "def bulk_add(index, docs):                            # ëŒ€ëŸ‰ ìƒ‰ì¸ì„ ìœ„í•œ í—¬í¼\n",
    "    actions = [{'_index': index, '_source': doc} for doc in docs]  # ì•¡ì…˜ ëª©ë¡ ìƒì„±\n",
    "    return helpers.bulk(es, actions)                  # helpers.bulk ë¡œ ì¼ê´„ ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec7d27",
   "metadata": {},
   "source": [
    "## ES ê²€ìƒ‰í•¨ìˆ˜\n",
    "1. sparse_retrieve(query_str, size)\n",
    "- query_str: ê²€ìƒ‰í•  í‚¤ì›Œë“œ(í…ìŠ¤íŠ¸).\n",
    "- size: ëª‡ ê°œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ì§€.\n",
    "- ì‘ë™ ë°©ì‹:\n",
    "    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ query_strì„ BM25 ë°©ì‹(ê¸°ë³¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰)ìœ¼ë¡œ content í•„ë“œì—ì„œ ë§¤ì¹­ì‹œí‚¨ë‹¤.\n",
    "    - _score ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ sizeë§Œí¼ ê°€ì ¸ì˜¨ë‹¤\n",
    "\n",
    "2. dense_retrieve(query_str, size)\n",
    "- query_str: ê²€ìƒ‰í•  í‚¤ì›Œë“œ(í…ìŠ¤íŠ¸).\n",
    "- size: ëª‡ ê°œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ì§€.\n",
    "- ì‘ë™ ë°©ì‹:\n",
    "    - query_strì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤.\n",
    "    - ì´ ë²¡í„°ì™€ ì¸ë±ìŠ¤ì— ì €ì¥ëœ ë¬¸ì„œë“¤ì˜ ë²¡í„°(embeddings)ë¥¼ ë¹„êµí•œë‹¤.\n",
    "    - ê°€ì¥ ê°€ê¹Œìš´(ìœ ì‚¬í•œ) ë¬¸ì„œ sizeê°œë¥¼ ê°€ì ¸ì˜¨ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9139f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_retrieve(query_str, size):                 # ì—­ìƒ‰ì¸(BM25) ê²€ìƒ‰\n",
    "    query = {\"match\": {\"content\": {\"query\": query_str}}}\n",
    "    return es.search(index=\"test\",\n",
    "                     query=query,\n",
    "                     size=size,\n",
    "                     sort=\"_score\")\n",
    "\n",
    "def dense_retrieve(query_str, size):                  # ë²¡í„° KNN ê²€ìƒ‰\n",
    "    query_embedding = get_embedding([query_str])[0]   # ì¿¼ë¦¬ ì„ë² ë”©\n",
    "    knn = {                                           # KNN íŒŒë¼ë¯¸í„°\n",
    "        \"field\": \"embeddings\",\n",
    "        \"query_vector\": query_embedding.tolist(),\n",
    "        \"k\": size,\n",
    "        \"num_candidates\": 100\n",
    "    }\n",
    "    return es.search(index=\"test\", knn=knn)           # ES 8.x KNN ê²€ìƒ‰ í˜¸ì¶œ\n",
    "\n",
    "def hybrid_retrieve(query_str, size):\n",
    "    \"\"\"\n",
    "    sparse(BM25) ê²€ìƒ‰ ê²°ê³¼ + dense(KNN) ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ \n",
    "    ë” ê°•ë ¥í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” hybrid retrieval í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    \n",
    "    # sparse(BM25) ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    sparse_result = sparse_retrieve(query_str, size)\n",
    "    \n",
    "    # dense(KNN) ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    dense_result = dense_retrieve(query_str, size)\n",
    "    \n",
    "    # ë¬¸ì„œ IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "    merged_hits = {}\n",
    "    \n",
    "    # sparse ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¨¼ì € ì²˜ë¦¬\n",
    "    for hit in sparse_result[\"hits\"][\"hits\"]:\n",
    "        doc_id = hit[\"_id\"]  # Elasticsearch ë‚´ë¶€ doc id\n",
    "        merged_hits[doc_id] = {\n",
    "            \"source\": hit[\"_source\"],  # ë¬¸ì„œ ë³¸ë¬¸\n",
    "            \"sparse_score\": hit[\"_score\"],  # sparse(BM25) ìŠ¤ì½”ì–´\n",
    "            \"dense_score\": 0.0  # ì´ˆê¸° dense ìŠ¤ì½”ì–´ëŠ” 0ìœ¼ë¡œ ì„¤ì •\n",
    "        }\n",
    "    \n",
    "    # dense ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬\n",
    "    for hit in dense_result[\"hits\"][\"hits\"]:\n",
    "        doc_id = hit[\"_id\"]  # Elasticsearch ë‚´ë¶€ doc id\n",
    "        if doc_id in merged_hits:\n",
    "            merged_hits[doc_id][\"dense_score\"] = hit[\"_score\"]  # ì´ë¯¸ ìˆëŠ” ê²½ìš° dense ìŠ¤ì½”ì–´ë§Œ ì¶”ê°€\n",
    "        else:\n",
    "            merged_hits[doc_id] = {\n",
    "                \"source\": hit[\"_source\"],  # ë¬¸ì„œ ë³¸ë¬¸\n",
    "                \"sparse_score\": 0.0,        # sparse ì ìˆ˜ëŠ” ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼\n",
    "                \"dense_score\": hit[\"_score\"]  # dense ìŠ¤ì½”ì–´ë§Œ ìˆëŠ” ë¬¸ì„œ\n",
    "            }\n",
    "    \n",
    "    # sparseì™€ dense ìŠ¤ì½”ì–´ë¥¼ ì¡°í•©í•´ì„œ ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    for doc_id in merged_hits:\n",
    "        # sparseì™€ dense ì ìˆ˜ë¥¼ ê°€ì¤‘ í‰ê·  (ë¹„ìœ¨ì€ ì¡°ì • ê°€ëŠ¥)\n",
    "        merged_hits[doc_id][\"final_score\"] = 0.5 * merged_hits[doc_id][\"sparse_score\"] + 0.5 * merged_hits[doc_id][\"dense_score\"]\n",
    "    \n",
    "    # ìµœì¢… ìŠ¤ì½”ì–´ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìˆœ)\n",
    "    ranked_hits = sorted(merged_hits.items(), key=lambda x: x[1][\"final_score\"], reverse=True)\n",
    "    \n",
    "    # top sizeê°œë§Œ ì„ íƒ\n",
    "    top_hits = ranked_hits[:size]\n",
    "    \n",
    "    # ì¶œë ¥ í˜•ì‹ì„ ê¸°ì¡´ Elasticsearch ê²€ìƒ‰ ê²°ê³¼ì²˜ëŸ¼ ë§ì¶”ê¸°\n",
    "    results = []\n",
    "    for doc_id, info in top_hits:\n",
    "        results.append({\n",
    "            \"_id\": doc_id,\n",
    "            \"_score\": info[\"final_score\"],\n",
    "            \"_source\": info[\"source\"]\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ca1a2",
   "metadata": {},
   "source": [
    "## ES í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "### ì„œë²„ ë²„ì „ê³¼ í˜¸í™˜ì´ ì•ˆë¨. ì½”ë“œ fix í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3690ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_username = \"elastic\"                               # ES ê¸°ë³¸ ì‚¬ìš©ì\n",
    "# es_password = \"ES_PASSWORD\"           # â† ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ êµì²´\n",
    "\n",
    "# es = Elasticsearch(                                   # í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "#     ['https://localhost:9200'],\n",
    "#     basic_auth=(es_username, es_password),\n",
    "#     ca_certs=\"./elasticsearch-8.8.0/config/certs/http_ca.crt\"\n",
    "# )\n",
    "# print(es.info())                                      # ì ‘ì† ì •ë³´ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f352dee",
   "metadata": {},
   "source": [
    "### í˜¸í™˜ ëª¨ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4279282",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_username = \"elastic\"                               # ES ê¸°ë³¸ ì‚¬ìš©ì\n",
    "es_password = ES_PASSWORD           # â† ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ë¡œ êµì²´\n",
    "\n",
    "es = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(es_username, es_password),\n",
    "    verify_certs=False,        # CA ë¬´ì‹œ(í…ŒìŠ¤íŠ¸ìš©)\n",
    ")\n",
    "\n",
    "print(es.info())  # ì´ì œ ì •ìƒ ì¶œë ¥ (ì˜ˆ: 7.17.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbf623",
   "metadata": {},
   "source": [
    "## ì¸ë±ìŠ¤ ì„¤ì • & ë§¤í•‘\n",
    "Elasticsearchì—ì„œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ + ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•  ìˆ˜ ìˆëŠ” ì¸ë±ìŠ¤ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ì„¤ì •.  \n",
    "\n",
    "1. settings ë¶€ë¶„\n",
    "- nori ë¶„ì„ê¸°ëŠ” Nori Tokenizerë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•¨.\n",
    "- ì¡°ì‚¬, ì–´ë¯¸, ê¸°í˜¸ ê°™ì€ ë¶ˆí•„ìš”í•œ í’ˆì‚¬ í† í°ì„ ì œê±°\n",
    "    - E(ì–´ë¯¸), J(ì¡°ì‚¬), SC(êµ¬ë‘ì ), SE(ë¬¸ì¥êµ¬ë¶„), SF(ë§ˆì¹¨í‘œ), VCN(í˜•ìš©ì‚¬), VCP(ê¸ì •ì§€ì •ì‚¬), VX(ë³´ì¡°ë™ì‚¬)\n",
    "- í•µì‹¬ ë˜ì–´ë§Œ ë‚¨ê¹€.\n",
    "\n",
    "2. mappings ë¶€ë¶„\n",
    "- content: ì¼ë°˜ í…ìŠ¤íŠ¸ í•„ë“œ, ê²€ìƒ‰í•  ë•Œ nori ë¶„ì„ê¸°ë¡œ ì „ì²˜ë¦¬ í•´ì„œ ì¸ë±ì‹±.\n",
    "- embeddings: 768 ì°¨ì› ë²¡í„° í•„ë“œë¥¼ ì €ì¥í•˜ê³ , ë²¡í„° ê²€ìƒ‰ì„ í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {                                          # í•œê¸€ìš© Nori ë¶„ì„ê¸° ì„¤ì •\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"nori\": {                               # 'nori'ë¼ëŠ” ì‚¬ìš©ì ì •ì˜ ë¶„ì„ê¸°ë¥¼ ë§Œë“ ë‹¤\n",
    "                \"type\": \"custom\",                   # ì§ì ‘ í•„í„°ì™€ í† í¬ë‚˜ì´ì €ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ì‹\n",
    "                \"tokenizer\": \"nori_tokenizer\",      # í•œêµ­ì–´ìš© ê¸°ë³¸ Nori í† í¬ë‚˜ì´ì € ì‚¬ìš©\n",
    "                \"decompound_mode\": \"mixed\",         # ë³µí•©ì–´ëŠ” ë¶„ë¦¬ë„ í•˜ê³  ì›í˜•ë„ ê°™ì´ ë³´ì¡´(mixed)\n",
    "                \"filter\": [\"nori_posfilter\", \"synonym_filter\"]        # í•„í„°ë§ ì ìš©\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        \"normalizer\": {\n",
    "            \"lowercase_normalizer\": {\n",
    "            \"type\": \"custom\",\n",
    "            \"filter\": [\"lowercase\"]\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"filter\": {\n",
    "            \"synonym_filter\": {\n",
    "                \"type\": \"synonym\",\n",
    "                # \"synonyms_path\": \"/usr/share/elasticsearch/config/synonym_filter.txt\", # íŒŒì¼ ê²½ë¡œ # í—¬ë¥¨, helium, HeLiUm\n",
    "                \"synonyms\": [\"ìš´ë™, ì²´ìœ¡, ìŠ¤í¬ì¸ \"] # í—¬ë¥¨, helium, HeLiUm\n",
    "                # \"updateable\": True  #  (7.3 ì´ìƒ) ë™ì  ì—…ë°ì´íŠ¸\n",
    "            },\n",
    "            \"nori_posfilter\": {  # ì‚¬ìš©ì ì •ì˜ í’ˆì‚¬ í•„í„°\n",
    "                \"type\": \"nori_part_of_speech\",  # í’ˆì‚¬ ê¸°ë°˜ í•„í„°ë§ì„ ìˆ˜í–‰\n",
    "                \"stoptags\": [\"E\", \"J\", \"SC\", \"SE\", \"SF\", \"VCN\", \"VCP\", \"VX\"]  \n",
    "                # ì´ í’ˆì‚¬ì— í•´ë‹¹í•˜ëŠ” í† í°ë“¤ì€ ì œê±°í•œë‹¤\n",
    "                # E(ì–´ë¯¸), J(ì¡°ì‚¬), SC(êµ¬ë‘ì ), SE(ë¬¸ì¥êµ¬ë¶„), SF(ë§ˆì¹¨í‘œ), VCN(í˜•ìš©ì‚¬), VCP(ê¸ì •ì§€ì •ì‚¬), VX(ë³´ì¡°ë™ì‚¬)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"content\": {\"type\": \"text\", \"analyzer\": \"nori\"},  # 'content' í•„ë“œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ nori ë¶„ì„ê¸°ë¡œ ë¶„ì„\n",
    "        \"embeddings\": {  \n",
    "            \"type\": \"dense_vector\",  # 'embeddings' í•„ë“œëŠ” ë°€ì§‘ ë²¡í„°(dense vector)ë¡œ ì €ì¥\n",
    "            \"dims\": 768,  # ì„ë² ë”© ë²¡í„° ì°¨ì› ìˆ˜ëŠ” 768 (ex: BERT base ëª¨ë¸ output ì°¨ì›)\n",
    "            \"index\": True,  # ë²¡í„°ë¥¼ ê²€ìƒ‰(indexing) ê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
    "            \"similarity\": \"l2_norm\"  # ë²¡í„° ìœ ì‚¬ë„ëŠ” L2 ë…¸ë¦„(ìœ í´ë¦¬ë“œ ê±°ë¦¬) ê¸°ë°˜ìœ¼ë¡œ ì¸¡ì •\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "create_es_index(\"test\", settings, mappings)           # â€˜testâ€™ ì¸ë±ìŠ¤ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fe681",
   "metadata": {},
   "source": [
    "## ë¬¸ì„œ ë¡œë“œ & ìƒ‰ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be547855",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_docs = []                                       # ìƒ‰ì¸ìš© ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "with jsonlines.open(\"./data/documents.jsonl\") as reader:\n",
    "    docs = list(reader)                # ê° ì¤„ì´ dictë¡œ ë°”ë¡œ ë³€í™˜ë¨\n",
    "\n",
    "embeddings = get_embeddings_in_batches(docs)          # ì„ë² ë”© ë°°ì¹˜ ìƒì„±\n",
    "\n",
    "for doc, emb in zip(docs, embeddings):                # ë¬¸ì„œì™€ ì„ë² ë”© ë³‘í•©\n",
    "    doc[\"embeddings\"] = emb.tolist()                  # numpy â†’ list ë³€í™˜\n",
    "    index_docs.append(doc)\n",
    "\n",
    "ret = bulk_add(\"test\", index_docs)                    # ESì— ëŒ€ëŸ‰ ìƒ‰ì¸\n",
    "print(ret)                                            # ìƒ‰ì¸ ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72deda",
   "metadata": {},
   "source": [
    "## ê²€ìƒ‰ ì˜ˆì‹œ ì‹¤í–‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"ê¸ˆì„±ì´ ë‹¤ë¥¸ í–‰ì„±ë“¤ë³´ë‹¤ ë°ê²Œ ë³´ì´ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"  # ìƒ˜í”Œ ì¿¼ë¦¬\n",
    "\n",
    "search_result_retrieve = sparse_retrieve(test_query, 3)  # BM25 ê²€ìƒ‰\n",
    "for hit in search_result_retrieve['hits']['hits']:       # ê²°ê³¼ ì¶œë ¥\n",
    "    print('sparse score:', hit['_score'],\n",
    "          'source:', hit['_source'][\"content\"])\n",
    "\n",
    "search_result_retrieve = dense_retrieve(test_query, 3)   # ë²¡í„° ê²€ìƒ‰\n",
    "for hit in search_result_retrieve['hits']['hits']:\n",
    "    print('dense score:', hit['_score'],\n",
    "          'source:', hit['_source'][\"content\"])\n",
    "    \n",
    "search_result_retrieve = hybrid_retrieve(test_query, 3)   # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "for hit in search_result_retrieve:\n",
    "    print('hybrid score:', hit['_score'],\n",
    "          'source:', hit['_source'][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9ae31",
   "metadata": {},
   "source": [
    "## OpenAI RAG ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI                             # OpenAI SDK\n",
    "import traceback                                      # ì˜ˆì™¸ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥ìš©\n",
    "\n",
    "os.environ[\"SOLAR_API_KEY\"] = SOLAR_API_KEY         # API í‚¤ í™˜ê²½ë³€ìˆ˜\n",
    "client = OpenAI(                                    # OPENAI API í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "    base_url=\"https://api.upstage.ai/v1/solar\",     # Upstage Solar API URL\n",
    "    api_key=SOLAR_API_KEY\n",
    ")\n",
    "llm_model = \"solar-pro\"                             # ì‚¬ìš©í•  LLM ì´ë¦„\n",
    "\n",
    "persona_qa = \"\"\"                                      # QAìš© í”„ë¡¬í”„íŠ¸\n",
    "## Role: ê²€ìƒ‰ ê¸°ë°˜ ê³¼í•™ ìƒì‹ ë‹µë³€ ì „ë¬¸ê°€\n",
    "\n",
    "## Instructions\n",
    "- ì œê³µëœ ê²€ìƒ‰ ë¬¸ì„œ(Reference)ì™€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "- ë°˜ë“œì‹œ ê²€ìƒ‰ ë¬¸ì„œì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•´ì•¼ í•˜ë©°, ë¬¸ì„œì— ì—†ìœ¼ë©´ \"ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "- ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. (3ë¬¸ì¥ ì´ë‚´)\n",
    "- ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ê²€ìƒ‰ ë¬¸ì„œê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‚´ìš©ì„ ìš°ì„  ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "persona_function_calling = \"\"\"\n",
    "## Role: ê³¼í•™ ìƒì‹ ê´€ë ¨ ì§ˆë¬¸ í•„í„°ë§ ì „ë¬¸ê°€\n",
    "\n",
    "## Instructions\n",
    "- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ê³¼í•™ ìƒì‹(ìì—° ê³¼í•™, ìƒëª… ê³¼í•™, ë¬¼ë¦¬í•™, í™”í•™, ì§€êµ¬ ê³¼í•™ ë“±)ê³¼ ê´€ë ¨ë˜ì–´ ìˆìœ¼ë©´ search APIë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n",
    "- ê³¼í•™ ìƒì‹ ì™¸(ì¼ìƒ ëŒ€í™”, ê°œì¸ ê°ì •, ë¬¸í•™, ì² í•™, ì‚¬íšŒ ì´ìŠˆ ë“±) ì§ˆë¬¸ì´ë¼ë©´ ì§ì ‘ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "- ê³¼í•™ ê´€ë ¨ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” search APIë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³ , \"ì§ˆë¬¸ì„ ëª…í™•íˆ í•´ì£¼ì„¸ìš”\"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "tools = [                                             # functionâ€‘calling ì •ì˜\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"ê³¼í•™ ìƒì‹ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ëŒ€í•´ ì í•©í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"standalone_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ê³¼í•™ ìƒì‹ ê´€ë ¨ í•œê¸€ ì§ˆë¬¸ì„ ëª…í™•í•˜ê²Œ ì…ë ¥í•˜ì„¸ìš”\"\n",
    "\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"standalone_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286baf36",
   "metadata": {},
   "source": [
    "### SOLAR CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913da268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_solar(messages, model=\"solar-1-mini-chat\", temperature=0.0, top_p=0.9):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {SOLAR_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"n\": 1\n",
    "    }\n",
    "    \n",
    "    response = requests.post(SOLAR_API_URL, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # âœ… ì—¬ê¸°! .text ë§ê³  .json()ìœ¼ë¡œ!!\n",
    "    else:\n",
    "        print(f\"Solar API Error {response.status_code}: {response.text}\")\n",
    "        raise Exception(f\"Solar API í˜¸ì¶œ ì‹¤íŒ¨ (status_code: {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c55557",
   "metadata": {},
   "source": [
    "## RAG í•µì‹¬ ë¡œì§\n",
    "### open_ai ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(messages):  # ëŒ€í™” ê¸°ë¡(messages)ì„ ì…ë ¥ ë°›ì•„ ë‹µë³€(response)ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    response = {  # ë°˜í™˜í•  ê²°ê³¼ë¥¼ ì €ì¥í•  ë¹ˆ response ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "        \"standalone_query\": \"\",  # ê²€ìƒ‰ìš© ìµœì¢… ì¿¼ë¦¬ ì €ì¥\n",
    "        \"topk\": [],              # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ docid ë¦¬ìŠ¤íŠ¸ ì €ì¥\n",
    "        \"references\": [],        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ scoreì™€ ë‚´ìš© ì €ì¥\n",
    "        \"answer\": \"\"             # ìµœì¢… ìƒì„±ëœ ë‹µë³€ ì €ì¥\n",
    "    }\n",
    "\n",
    "    msg = [{\"role\": \"system\", \"content\": persona_function_calling}] + messages  # ê²€ìƒ‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•  system í”„ë¡¬í”„íŠ¸ì™€ ìœ ì € ë©”ì‹œì§€ë¥¼ í•©ì¹œë‹¤\n",
    "    try:  # 1ì°¨ GPT í˜¸ì¶œì„ ì‹œë„\n",
    "        result = client.chat.completions.create(  # OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ LLM í˜¸ì¶œ\n",
    "            model=llm_model,                      # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ ì„¤ì •\n",
    "            messages=msg,                         # ì…ë ¥ ë©”ì‹œì§€ ì„¤ì •\n",
    "            tools=tools,                          # function-callingìš© tool ì„¤ì •\n",
    "            temperature=0,                        # ëœë¤ì„± ìµœì†Œí™” (0ìœ¼ë¡œ ì„¤ì •)\n",
    "            seed=1,                               # ê²°ê³¼ ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •\n",
    "            timeout=10                            # API í˜¸ì¶œ ì œí•œ ì‹œê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)\n",
    "        )\n",
    "    except Exception:  # ì˜ˆì™¸ê°€ ë°œìƒí–ˆì„ ë•Œ\n",
    "        traceback.print_exc()  # ì—ëŸ¬ ë¡œê·¸ë¥¼ ì¶œë ¥\n",
    "        response[\"answer\"] = \"ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"  # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë‹µë³€ì— ì„¤ì •\n",
    "        return response  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ response ë°˜í™˜\n",
    "\n",
    "    if result.choices[0].message.tool_calls:  # tool_callì´ ì¡´ì¬í•˜ë©´ â†’ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°\n",
    "        tool_call = result.choices[0].message.tool_calls[0]  # ì²« ë²ˆì§¸ tool_callì„ ê°€ì ¸ì˜¨ë‹¤\n",
    "        args = json.loads(tool_call.function.arguments)  # tool_call ì•ˆì˜ argumentsë¥¼ íŒŒì‹±í•´ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "        query = args.get(\"standalone_query\")  # ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¥¼ ê°€ì ¸ì˜¨ë‹¤\n",
    "\n",
    "        search_result = sparse_retrieve(query, 3)  # BM25 ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ 3ê°œë¥¼ ì°¾ëŠ”ë‹¤\n",
    "        response[\"standalone_query\"] = query  # responseì— ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê¸°ë¡í•œë‹¤\n",
    "\n",
    "        context = []  # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë³¸ë¬¸ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        for hit in search_result['hits']['hits']:  # ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "            context.append(hit[\"_source\"][\"content\"])  # ë¬¸ì„œ ë‚´ìš©ì„ context ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            response[\"topk\"].append(hit[\"_source\"][\"docid\"])  # ë¬¸ì„œì˜ docidë¥¼ topk ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "            response[\"references\"].append({  # ë¬¸ì„œì˜ scoreì™€ contentë¥¼ references ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "                \"score\": hit[\"_score\"], \n",
    "                \"content\": hit[\"_source\"][\"content\"]\n",
    "            })\n",
    "\n",
    "        messages.append({  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ Assistant ë©”ì‹œì§€ë¡œ ì¶”ê°€\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": json.dumps(context)  # ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©ì„ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì‚½ì…\n",
    "        })\n",
    "        qa_msg = [{\"role\": \"system\", \"content\": persona_qa}] + messages  # QA ìƒì„±ìš© system í”„ë¡¬í”„íŠ¸ì™€ ë©”ì‹œì§€ë“¤ì„ í•©ì¹œë‹¤\n",
    "\n",
    "        try:  # 2ì°¨ GPT í˜¸ì¶œì„ ì‹œë„ (ìµœì¢… ë‹µë³€ ìƒì„±)\n",
    "            qa_res = client.chat.completions.create(\n",
    "                model=llm_model,              # ì‚¬ìš©í•  ëª¨ë¸ ì„¤ì •\n",
    "                messages=qa_msg,               # ê²€ìƒ‰ ë¬¸ì„œë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ì „ë‹¬\n",
    "                temperature=0,                 # ëœë¤ì„± ìµœì†Œí™”\n",
    "                seed=1,                        # ê²°ê³¼ ì¬í˜„ì„± í™•ë³´\n",
    "                timeout=30                     # API í˜¸ì¶œ ì œí•œ ì‹œê°„ ì„¤ì •\n",
    "            )\n",
    "        except Exception:  # ì˜ˆì™¸ ë°œìƒ ì‹œ\n",
    "            traceback.print_exc()  # ì—ëŸ¬ ë¡œê·¸ë¥¼ ì¶œë ¥\n",
    "            return response  # ì˜¤ë¥˜ ë°œìƒ ì‹œ í˜„ì¬ê¹Œì§€ì˜ response ë°˜í™˜\n",
    "\n",
    "        response[\"answer\"] = qa_res.choices[0].message.content  # ìµœì¢… ìƒì„±ëœ ë‹µë³€ì„ responseì— ì €ì¥\n",
    "    else:  # tool_callì´ ì—†ìœ¼ë©´ â†’ ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ë‹µë³€\n",
    "        response[\"answer\"] = result.choices[0].message.content  # 1ì°¨ í˜¸ì¶œ ê²°ê³¼ë¡œ ë°”ë¡œ ë‹µë³€ ì„¤ì •\n",
    "\n",
    "    return response  # ìµœì¢… ìƒì„±ëœ response ë°˜í™˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766ad76",
   "metadata": {},
   "source": [
    "### SOLAR_API ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(messages):\n",
    "    response = {\"standalone_query\": \"\", \"topk\": [], \"references\": [], \"answer\": \"\"}\n",
    "\n",
    "    # 1ì°¨ í˜¸ì¶œ (ê²€ìƒ‰ ì—¬ë¶€ íŒë‹¨)\n",
    "    msg = [{\"role\": \"system\", \"content\": persona_function_calling}] + messages\n",
    "    try:\n",
    "        result_json = call_solar(msg, model=llm_model, temperature=0.0)  # ì´ë¯¸ dictë¡œ ë°˜í™˜ë¨\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        response[\"answer\"] = \"ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "        return response\n",
    "\n",
    "    message = result_json[\"choices\"][0][\"message\"]  # âœ… Solar ê²°ê³¼ ì ‘ê·¼\n",
    "    tool_calls = message.get(\"tool_calls\", None)    # tool_calls ìˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "    # tool_callsê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ í•„ìš”\n",
    "    if tool_calls:\n",
    "        tool_call = tool_calls[0]\n",
    "        args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "        query = args.get(\"standalone_query\")\n",
    "\n",
    "        search_result = sparse_retrieve(query, 3)\n",
    "        response[\"standalone_query\"] = query\n",
    "\n",
    "        context = []\n",
    "        for hit in search_result['hits']['hits']:\n",
    "            context.append(hit[\"_source\"][\"content\"])\n",
    "            response[\"topk\"].append(hit[\"_source\"][\"docid\"])\n",
    "            response[\"references\"].append({\n",
    "                \"score\": hit[\"_score\"],\n",
    "                \"content\": hit[\"_source\"][\"content\"]\n",
    "            })\n",
    "\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": json.dumps(context)\n",
    "        })\n",
    "        qa_msg = [{\"role\": \"system\", \"content\": persona_qa}] + messages\n",
    "\n",
    "        # 2ì°¨ í˜¸ì¶œ (ìµœì¢… ë‹µë³€ ìƒì„±)\n",
    "        try:\n",
    "            qa_result_json = call_solar(qa_msg, model=llm_model, temperature=0.0)\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            return response\n",
    "\n",
    "        response[\"answer\"] = qa_result_json[\"choices\"][0][\"message\"][\"content\"]  # âœ… ìµœì¢… ë‹µë³€ ë½‘ê¸°\n",
    "    else:\n",
    "        # ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ë‹µë³€\n",
    "        response[\"answer\"] = message[\"content\"]\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4b9a4",
   "metadata": {},
   "source": [
    "## í‰ê°€ ë£¨í”„ \n",
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rag(eval_filename, output_filename):  # í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "    with jsonlines.open(eval_filename) as reader, open(output_filename, \"w\") as of:  \n",
    "        # ì…ë ¥ íŒŒì¼(eval_filename)ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê³ , ì¶œë ¥ íŒŒì¼(output_filename)ì„ ì“°ê¸° ëª¨ë“œë¡œ ì—°ë‹¤\n",
    "        for idx, j in enumerate(reader):  # ì…ë ¥ íŒŒì¼ì—ì„œ í•œ ì¤„ì”© ì½ì–´ì˜¤ê³ , ì¸ë±ìŠ¤(idx)ì™€ ë‚´ìš©(j)ì„ ê°€ì ¸ì˜¨ë‹¤\n",
    "            print(f'Test {idx}\\nQuestion: {j[\"msg\"]}')  # í˜„ì¬ í…ŒìŠ¤íŠ¸ ë²ˆí˜¸ì™€ ì§ˆë¬¸ ë‚´ìš©ì„ ì¶œë ¥í•œë‹¤\n",
    "            \n",
    "            resp = answer_question(j[\"msg\"])  # í˜„ì¬ ì§ˆë¬¸(j[\"msg\"])ì— ëŒ€í•´ RAG ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ì—¬ ì‘ë‹µ(resp)ì„ ìƒì„±í•œë‹¤\n",
    "            \n",
    "            print(f'Answer: {resp[\"answer\"]}\\n')  # ìƒì„±ëœ ë‹µë³€ì„ ì¶œë ¥í•œë‹¤\n",
    "\n",
    "            out = {  # ì œì¶œ íŒŒì¼ì— ì“¸ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì •ë¦¬í•œë‹¤\n",
    "                \"eval_id\": j[\"eval_id\"],  # í‰ê°€ ì•„ì´ë”” (ë¬¸ì œ ê³ ìœ  ì‹ë³„ì)\n",
    "                \"standalone_query\": resp[\"standalone_query\"],  # ìƒì„±ëœ ê²€ìƒ‰ìš© ìµœì¢… ì¿¼ë¦¬\n",
    "                \"topk\": resp[\"topk\"],  # ê²€ìƒ‰í•´ì„œ ê°€ì ¸ì˜¨ ë¬¸ì„œë“¤ì˜ docid ë¦¬ìŠ¤íŠ¸\n",
    "                \"answer\": resp[\"answer\"],  # ìµœì¢… ìƒì„±ëœ ë‹µë³€ í…ìŠ¤íŠ¸\n",
    "                \"references\": resp[\"references\"]  # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ìŠ¤ì½”ì–´ ë° ë‚´ìš© ë¦¬ìŠ¤íŠ¸\n",
    "            }\n",
    "            \n",
    "            of.write(json.dumps(out, ensure_ascii=False) + \"\\n\")  \n",
    "            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬(out)ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•´ ì¶œë ¥ íŒŒì¼ì— í•œ ì¤„ì”© ì €ì¥í•œë‹¤\n",
    "\n",
    "            time.sleep(2.0)  # âœ… ìš”ì²­ ì‚¬ì´ ë”œë ˆì´ ì¡°ê¸ˆ ì—¬ìœ ìˆê²Œ (2ì´ˆ)\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "eval_rag(\"./data/eval.jsonl\", \"sample_submission.csv\")  # ìœ„ì—ì„œ ì •ì˜í•œ eval_rag í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í‰ê°€ë¥¼ ì‹œì‘í•œë‹¤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5b0f9",
   "metadata": {},
   "source": [
    "### SOLAR_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def eval_rag(eval_filename, output_filename):\n",
    "    with jsonlines.open(eval_filename) as reader, open(output_filename, \"w\") as of:\n",
    "        for idx, j in enumerate(reader):\n",
    "            print(f'Test {idx}\\nQuestion: {j[\"msg\"]}')\n",
    "            \n",
    "            try:\n",
    "                resp = answer_question(j[\"msg\"])  # Solar APIë¥¼ ì‚¬ìš©í•˜ëŠ” answer_question í˜¸ì¶œ\n",
    "            except Exception as e:\n",
    "                print(f\"Error during answering: {e}\")\n",
    "                resp = {\"standalone_query\": \"\", \"topk\": [], \"references\": [], \"answer\": \"ë‹µë³€ ìƒì„± ì‹¤íŒ¨\"}\n",
    "\n",
    "            print(f'Answer: {resp[\"answer\"]}\\n')\n",
    "\n",
    "            out = {\n",
    "                \"eval_id\": j[\"eval_id\"],\n",
    "                \"standalone_query\": resp[\"standalone_query\"],\n",
    "                \"topk\": resp[\"topk\"],\n",
    "                \"answer\": resp[\"answer\"],\n",
    "                \"references\": resp[\"references\"]\n",
    "            }\n",
    "            of.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            time.sleep(1.5)  # âœ… ìš”ì²­ ê°„ ë”œë ˆì´ ì¶”ê°€\n",
    "\n",
    "eval_rag(\"./data/eval1.jsonl\", \"sample_submission2.csv\")  # ìœ„ì—ì„œ ì •ì˜í•œ eval_rag í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í‰ê°€ë¥¼ ì‹œì‘í•œë‹¤\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
